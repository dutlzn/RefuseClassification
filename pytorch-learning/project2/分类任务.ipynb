{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist分类任务：\n",
    "\n",
    "- 网络基本构建与训练方法，常用函数解析\n",
    "\n",
    "- torch.nn.functional模块\n",
    "\n",
    "- nn.Module模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取Mnist数据集\n",
    "- 会自动进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(r\"d:/ai/data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784是mnist数据集每个样本的像素点个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(50000, 784)\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (http://matplotlib.org/) -->\r\n<svg height=\"252.018125pt\" version=\"1.1\" viewBox=\"0 0 255.065 252.018125\" width=\"255.065pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 252.018125 \r\nL 255.065 252.018125 \r\nL 255.065 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 228.14 \r\nL 244.365 228.14 \r\nL 244.365 10.7 \r\nL 26.925 10.7 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pdbc2a92430)\">\r\n    <image height=\"218\" id=\"image65f87a4143\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-10.14\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m6429b19024\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m6429b19024\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-30\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.626607 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m6429b19024\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-35\"/>\r\n      </defs>\r\n      <g transform=\"translate(66.455179 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m6429b19024\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-31\"/>\r\n      </defs>\r\n      <g transform=\"translate(102.1025 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m6429b19024\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m6429b19024\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-32\"/>\r\n      </defs>\r\n      <g transform=\"translate(179.759643 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m6429b19024\" y=\"228.14\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 242.738437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mff40c04bbb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mff40c04bbb\" y=\"14.582857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 18.382076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mff40c04bbb\" y=\"53.411429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 57.210647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mff40c04bbb\" y=\"92.24\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 96.039219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mff40c04bbb\" y=\"131.068571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 134.86779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mff40c04bbb\" y=\"169.897143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 173.696362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mff40c04bbb\" y=\"208.725714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 212.524933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 228.14 \r\nL 26.925 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 228.14 \r\nL 244.365 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 228.14 \r\nL 244.365 228.14 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 10.7 \r\nL 244.365 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pdbc2a92430\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"10.7\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[1].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\ntorch.Size([50000, 784])\ntensor(0) tensor(9)\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional 很多层和函数在这里都会见到\n",
    "\n",
    "torch.nn.functional中有很多功能，后续会常用的。那什么时候使用nn.Module，什么时候使用nn.functional呢？一般情况下，如果模型有可学习的参数，最好用nn.Module，其他情况nn.functional相对更简单一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb.mm(weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(14.7869, grad_fn=<NllLossBackward>)\n"
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]\n",
    "weights = torch.randn([784, 10], dtype = torch.float,  requires_grad = True) \n",
    "bs = 64\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个model来更简化代码\n",
    "- 必须继承nn.Module且在其构造函数中需调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.hidden3 = nn.Linear(256,128)\n",
    "        self.out  = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mnist_NN(\n  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n  (hidden3): Linear(in_features=256, out_features=128, bias=True)\n  (out): Linear(in_features=128, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以打印我们定义好名字里的权重和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hidden1.weight Parameter containing:\ntensor([[ 0.0012,  0.0087,  0.0093,  ..., -0.0068, -0.0167,  0.0016],\n        [ 0.0299, -0.0014, -0.0102,  ..., -0.0013,  0.0013,  0.0071],\n        [ 0.0329, -0.0090,  0.0219,  ...,  0.0279, -0.0187,  0.0117],\n        ...,\n        [ 0.0352, -0.0028, -0.0206,  ..., -0.0285, -0.0339, -0.0291],\n        [ 0.0087,  0.0245,  0.0039,  ...,  0.0305,  0.0190,  0.0316],\n        [-0.0323,  0.0225,  0.0024,  ...,  0.0179,  0.0139, -0.0003]],\n       requires_grad=True) torch.Size([128, 784])\nhidden1.bias Parameter containing:\ntensor([-1.3941e-02,  3.5412e-02,  2.1924e-03, -3.0893e-03,  1.2293e-02,\n         1.9652e-02,  3.2271e-02,  1.6552e-04, -2.6471e-03, -3.7664e-03,\n         2.3502e-02, -3.1039e-02,  3.5953e-03, -1.0211e-02, -6.4860e-03,\n         1.0292e-02, -8.7408e-03, -1.6504e-02, -5.4387e-03, -2.9491e-02,\n         2.5101e-02, -2.0024e-02,  1.9610e-02, -1.7060e-02,  2.8401e-02,\n        -3.0549e-02,  3.8871e-03,  2.3344e-02, -2.9895e-02, -1.2420e-02,\n         4.1910e-03,  2.3169e-02,  1.8426e-02, -7.0617e-03,  2.4883e-02,\n        -9.4893e-03, -2.2377e-03,  4.7877e-03,  1.3539e-02,  5.7683e-03,\n        -2.1813e-02,  6.2543e-03, -3.3352e-03,  3.1030e-02, -3.4613e-02,\n         1.0171e-02,  3.5596e-02, -2.9125e-02,  5.6453e-03, -4.5303e-04,\n        -1.4414e-02, -1.0806e-02, -7.7626e-03,  2.7368e-02, -1.2570e-02,\n         1.9398e-02,  3.5548e-02,  6.9202e-03,  2.9460e-02, -1.6231e-02,\n        -2.3104e-02, -8.1812e-03, -3.2387e-03,  1.4712e-02, -2.8493e-02,\n         1.4059e-02, -1.6300e-02, -3.9163e-03,  1.6707e-02, -1.4604e-02,\n         1.7924e-02, -3.1811e-02,  2.6504e-02,  4.9607e-03, -1.6296e-02,\n         2.2088e-02,  2.8717e-03,  1.7385e-02, -2.5016e-02,  1.1536e-02,\n         6.4866e-03,  1.3480e-02,  5.6119e-04,  2.7245e-03, -7.1175e-03,\n         2.1133e-02, -1.8294e-02,  2.9243e-02,  2.0864e-02,  3.1485e-02,\n        -3.0969e-02, -2.0774e-03,  2.8246e-02, -3.2601e-02, -1.2373e-02,\n         3.4545e-02,  3.1362e-02, -5.2710e-03, -2.7913e-02, -1.3075e-02,\n        -3.4276e-04, -1.3561e-02,  3.3224e-02, -7.8398e-03,  2.8734e-02,\n        -2.1292e-03,  6.5218e-03, -3.2930e-02, -2.8862e-02, -1.8487e-02,\n         3.3169e-02, -1.7484e-02, -1.4321e-02,  2.0323e-02,  3.4055e-02,\n         2.6890e-02,  2.7362e-02,  2.3826e-02,  2.4107e-02,  4.5555e-03,\n        -1.4485e-02, -1.9265e-02,  8.3111e-05, -4.7511e-03, -2.7898e-02,\n        -2.8089e-02,  3.1309e-03,  3.1730e-02], requires_grad=True) torch.Size([128])\nhidden2.weight Parameter containing:\ntensor([[-0.0705,  0.0884, -0.0527,  ...,  0.0079, -0.0857,  0.0514],\n        [ 0.0405,  0.0035, -0.0247,  ..., -0.0383,  0.0701,  0.0560],\n        [ 0.0309, -0.0725, -0.0800,  ...,  0.0433,  0.0668,  0.0070],\n        ...,\n        [ 0.0475,  0.0378, -0.0437,  ..., -0.0670,  0.0310, -0.0640],\n        [ 0.0768,  0.0420,  0.0592,  ...,  0.0828, -0.0067, -0.0058],\n        [ 0.0250,  0.0560,  0.0050,  ..., -0.0853, -0.0226,  0.0771]],\n       requires_grad=True) torch.Size([256, 128])\nhidden2.bias Parameter containing:\ntensor([-0.0493,  0.0169,  0.0678,  0.0051, -0.0219, -0.0712, -0.0236,  0.0638,\n         0.0739, -0.0322, -0.0386,  0.0165,  0.0087, -0.0618,  0.0574, -0.0562,\n        -0.0716, -0.0554,  0.0734,  0.0088, -0.0713,  0.0518,  0.0120, -0.0081,\n         0.0775, -0.0382, -0.0328,  0.0554, -0.0833,  0.0694, -0.0612,  0.0670,\n        -0.0871,  0.0553, -0.0130, -0.0760,  0.0200, -0.0552,  0.0346, -0.0700,\n         0.0766, -0.0858, -0.0624,  0.0456,  0.0422, -0.0026, -0.0749, -0.0029,\n        -0.0683, -0.0750, -0.0642, -0.0523, -0.0843,  0.0121, -0.0083, -0.0815,\n         0.0529, -0.0820, -0.0532,  0.0614,  0.0174, -0.0155,  0.0809,  0.0519,\n        -0.0351,  0.0735, -0.0314,  0.0110, -0.0623,  0.0388,  0.0146, -0.0743,\n         0.0030, -0.0213, -0.0414, -0.0721,  0.0640,  0.0411, -0.0433, -0.0610,\n        -0.0585,  0.0370, -0.0838,  0.0248, -0.0522,  0.0530, -0.0805,  0.0782,\n         0.0221,  0.0777, -0.0154,  0.0658,  0.0127,  0.0017, -0.0411, -0.0214,\n        -0.0054, -0.0441,  0.0809, -0.0670, -0.0221, -0.0586, -0.0303,  0.0385,\n         0.0797,  0.0704,  0.0152, -0.0165, -0.0386,  0.0551,  0.0159,  0.0311,\n         0.0544, -0.0789,  0.0559, -0.0070,  0.0804, -0.0083, -0.0739,  0.0079,\n         0.0161,  0.0031,  0.0079,  0.0752,  0.0255,  0.0828,  0.0611, -0.0853,\n        -0.0432, -0.0360, -0.0206, -0.0716, -0.0591, -0.0532, -0.0087, -0.0138,\n        -0.0260, -0.0596, -0.0010, -0.0111, -0.0378, -0.0512, -0.0684, -0.0184,\n         0.0436, -0.0362, -0.0683, -0.0822,  0.0214, -0.0276, -0.0740, -0.0386,\n         0.0689, -0.0087,  0.0404,  0.0682,  0.0584,  0.0580, -0.0743,  0.0348,\n        -0.0343,  0.0376,  0.0298,  0.0691, -0.0823,  0.0397,  0.0556,  0.0034,\n        -0.0123, -0.0392,  0.0271,  0.0555, -0.0170, -0.0148, -0.0124,  0.0337,\n         0.0138, -0.0480,  0.0217,  0.0672, -0.0842, -0.0028, -0.0053,  0.0114,\n         0.0258, -0.0643,  0.0723,  0.0517,  0.0212,  0.0753, -0.0466,  0.0133,\n        -0.0436,  0.0801, -0.0556,  0.0730, -0.0565,  0.0315,  0.0331,  0.0142,\n        -0.0064,  0.0224,  0.0224,  0.0648, -0.0378, -0.0785,  0.0839,  0.0069,\n         0.0133,  0.0251,  0.0785,  0.0712, -0.0778,  0.0128,  0.0393, -0.0028,\n         0.0319, -0.0305, -0.0246, -0.0535, -0.0462, -0.0141, -0.0191, -0.0503,\n         0.0198, -0.0545, -0.0433,  0.0402, -0.0018,  0.0776, -0.0512, -0.0600,\n         0.0459, -0.0331,  0.0435, -0.0437,  0.0120, -0.0619, -0.0242, -0.0742,\n         0.0730,  0.0882,  0.0542,  0.0133,  0.0168,  0.0275, -0.0542,  0.0176,\n         0.0743, -0.0882,  0.0478, -0.0688,  0.0077,  0.0858, -0.0762, -0.0632],\n       requires_grad=True) torch.Size([256])\nhidden3.weight Parameter containing:\ntensor([[-0.0482,  0.0541, -0.0231,  ...,  0.0578,  0.0550, -0.0620],\n        [-0.0078,  0.0387, -0.0104,  ..., -0.0415,  0.0529, -0.0255],\n        [-0.0017,  0.0594, -0.0013,  ...,  0.0391, -0.0149, -0.0002],\n        ...,\n        [-0.0163,  0.0018, -0.0601,  ...,  0.0431, -0.0166,  0.0589],\n        [ 0.0410,  0.0274,  0.0098,  ...,  0.0456, -0.0022, -0.0310],\n        [ 0.0584, -0.0226, -0.0079,  ...,  0.0277,  0.0148,  0.0221]],\n       requires_grad=True) torch.Size([128, 256])\nhidden3.bias Parameter containing:\ntensor([ 0.0493, -0.0174, -0.0581,  0.0581,  0.0337,  0.0024,  0.0220,  0.0486,\n         0.0488, -0.0007,  0.0575,  0.0443,  0.0486, -0.0292, -0.0373,  0.0289,\n        -0.0534, -0.0082, -0.0150, -0.0620, -0.0395,  0.0060,  0.0311, -0.0609,\n        -0.0285, -0.0605, -0.0043,  0.0299, -0.0603, -0.0262,  0.0081,  0.0213,\n        -0.0322, -0.0172, -0.0517, -0.0473,  0.0357, -0.0367, -0.0318,  0.0139,\n         0.0240, -0.0402, -0.0518, -0.0473,  0.0035,  0.0373, -0.0565,  0.0186,\n        -0.0165,  0.0493, -0.0065,  0.0310, -0.0289, -0.0346, -0.0195, -0.0207,\n        -0.0348, -0.0100,  0.0072, -0.0171, -0.0145,  0.0524,  0.0175,  0.0533,\n         0.0375,  0.0411, -0.0284, -0.0604, -0.0150, -0.0053, -0.0337, -0.0376,\n         0.0483,  0.0584,  0.0112, -0.0614,  0.0609,  0.0059,  0.0436,  0.0606,\n        -0.0621, -0.0156,  0.0389, -0.0156,  0.0551,  0.0202,  0.0406, -0.0565,\n        -0.0594, -0.0532,  0.0003,  0.0366,  0.0438, -0.0242,  0.0381,  0.0215,\n         0.0373, -0.0593,  0.0341, -0.0081, -0.0280,  0.0170,  0.0477, -0.0105,\n        -0.0344, -0.0153,  0.0465,  0.0179,  0.0451,  0.0282, -0.0223,  0.0465,\n         0.0476, -0.0525, -0.0615,  0.0460, -0.0525, -0.0536, -0.0103, -0.0491,\n        -0.0237, -0.0535,  0.0387, -0.0316,  0.0421,  0.0067, -0.0552,  0.0165],\n       requires_grad=True) torch.Size([128])\nout.weight Parameter containing:\ntensor([[ 0.0453, -0.0436, -0.0304,  ..., -0.0716, -0.0247,  0.0300],\n        [-0.0502,  0.0431,  0.0194,  ...,  0.0531, -0.0168, -0.0277],\n        [-0.0180, -0.0629,  0.0845,  ...,  0.0801, -0.0685,  0.0224],\n        ...,\n        [ 0.0276, -0.0577,  0.0729,  ...,  0.0367, -0.0290,  0.0593],\n        [ 0.0234, -0.0359, -0.0388,  ...,  0.0025,  0.0348, -0.0816],\n        [ 0.0394, -0.0028,  0.0876,  ...,  0.0857,  0.0612,  0.0525]],\n       requires_grad=True) torch.Size([10, 128])\nout.bias Parameter containing:\ntensor([ 0.0591,  0.0357, -0.0215,  0.0226, -0.0813, -0.0385,  0.0748, -0.0389,\n        -0.0343, -0.0347], requires_grad=True) torch.Size([10])\n"
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter,parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用TensorDataset和DataLoader来简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般在训练模型时加上model.train()，这样会正常使用Batch Normalization和 Dropout\n",
    "测试的时候一般选择model.eval()，这样就不会使用Batch Normalization和 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "    return model, optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "当前step:0 验证集损失：2.297707787322998\n当前step:1 验证集损失：2.292704954147339\n当前step:2 验证集损失：2.286922444152832\n当前step:3 验证集损失：2.279571347808838\n当前step:4 验证集损失：2.2696795379638672\n当前step:5 验证集损失：2.2557113697052\n当前step:6 验证集损失：2.2351704948425293\n当前step:7 验证集损失：2.2036049072265627\n当前step:8 验证集损失：2.1529009628295896\n当前step:9 验证集损失：2.0689788524627684\n当前step:10 验证集损失：1.9320199981689452\n当前step:11 验证集损失：1.731125948524475\n当前step:12 验证集损失：1.4865883443832397\n当前step:13 验证集损失：1.2484342599868774\n当前step:14 验证集损失：1.0527401950836182\n当前step:15 验证集损失：0.9047937299728394\n当前step:16 验证集损失：0.7997488059043885\n当前step:17 验证集损失：0.7258606749534607\n当前step:18 验证集损失：0.671599135017395\n当前step:19 验证集损失：0.6285100969314575\n当前step:20 验证集损失：0.5949623084545136\n当前step:21 验证集损失：0.5663422867298126\n当前step:22 验证集损失：0.5410304470062256\n当前step:23 验证集损失：0.5193898627281189\n当前step:24 验证集损失：0.5007767448425293\n"
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(25, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596942964013",
   "display_name": "Python 3.7.0 64-bit ('Continuum': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['其他垃圾', 0, 0], ['其他垃圾', 0, 1], ['其他垃圾', 0, 2], ['其他垃圾', 0, 3], ['其他垃圾', 0, 4], ['其他垃圾', 0, 5], ['厨余垃圾', 1, 6], ['厨余垃圾', 1, 7], ['厨余垃圾', 1, 8], ['厨余垃圾', 1, 9], ['厨余垃圾', 1, 10], ['厨余垃圾', 1, 11], ['厨余垃圾', 1, 12], ['厨余垃圾', 1, 13], ['可回收物', 2, 14], ['可回收物', 2, 15], ['可回收物', 2, 16], ['可回收物', 2, 17], ['可回收物', 2, 18], ['可回收物', 2, 19], ['可回收物', 2, 20], ['可回收物', 2, 21], ['可回收物', 2, 22], ['可回收物', 2, 23], ['可回收物', 2, 24], ['可回收物', 2, 25], ['可回收物', 2, 26], ['可回收物', 2, 27], ['可回收物', 2, 28], ['可回收物', 2, 29], ['可回收物', 2, 30], ['可回收物', 2, 31], ['可回收物', 2, 32], ['可回收物', 2, 33], ['可回收物', 2, 34], ['可回收物', 2, 35], ['可回收物', 2, 36], ['有害垃圾', 3, 37], ['有害垃圾', 3, 38], ['有害垃圾', 3, 39]]\n{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 2, 16: 2, 17: 2, 18: 2, 19: 2, 20: 2, 21: 2, 22: 2, 23: 2, 24: 2, 25: 2, 26: 2, 27: 2, 28: 2, 29: 2, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 3, 38: 3, 39: 3}\n"
    }
   ],
   "source": [
    "garbage_classify_rule = {\n",
    "    \"0\": \"其他垃圾/一次性快餐盒\",\n",
    "    \"1\": \"其他垃圾/污损塑料\",\n",
    "    \"2\": \"其他垃圾/烟蒂\",\n",
    "    \"3\": \"其他垃圾/牙签\",\n",
    "    \"4\": \"其他垃圾/破碎花盆及碟碗\",\n",
    "    \"5\": \"其他垃圾/竹筷\",\n",
    "    \"6\": \"厨余垃圾/剩饭剩菜\",\n",
    "    \"7\": \"厨余垃圾/大骨头\",\n",
    "    \"8\": \"厨余垃圾/水果果皮\",\n",
    "    \"9\": \"厨余垃圾/水果果肉\",\n",
    "    \"10\": \"厨余垃圾/茶叶渣\",\n",
    "    \"11\": \"厨余垃圾/菜叶菜根\",\n",
    "    \"12\": \"厨余垃圾/蛋壳\",\n",
    "    \"13\": \"厨余垃圾/鱼骨\",\n",
    "    \"14\": \"可回收物/充电宝\",\n",
    "    \"15\": \"可回收物/包\",\n",
    "    \"16\": \"可回收物/化妆品瓶\",\n",
    "    \"17\": \"可回收物/塑料玩具\",\n",
    "    \"18\": \"可回收物/塑料碗盆\",\n",
    "    \"19\": \"可回收物/塑料衣架\",\n",
    "    \"20\": \"可回收物/快递纸袋\",\n",
    "    \"21\": \"可回收物/插头电线\",\n",
    "    \"22\": \"可回收物/旧衣服\",\n",
    "    \"23\": \"可回收物/易拉罐\",\n",
    "    \"24\": \"可回收物/枕头\",\n",
    "    \"25\": \"可回收物/毛绒玩具\",\n",
    "    \"26\": \"可回收物/洗发水瓶\",\n",
    "    \"27\": \"可回收物/玻璃杯\",\n",
    "    \"28\": \"可回收物/皮鞋\",\n",
    "    \"29\": \"可回收物/砧板\",\n",
    "    \"30\": \"可回收物/纸板箱\",\n",
    "    \"31\": \"可回收物/调料瓶\",\n",
    "    \"32\": \"可回收物/酒瓶\",\n",
    "    \"33\": \"可回收物/金属食品罐\",\n",
    "    \"34\": \"可回收物/锅\",\n",
    "    \"35\": \"可回收物/食用油桶\",\n",
    "    \"36\": \"可回收物/饮料瓶\",\n",
    "    \"37\": \"有害垃圾/干电池\",\n",
    "    \"38\": \"有害垃圾/软膏\",\n",
    "    \"39\": \"有害垃圾/过期药物\"\n",
    "}\n",
    "\n",
    "garbage_classify_index = {\"0\": \"其他垃圾\", \"1\": \"厨余垃圾\", \"2\": \"可回收物\", \"3\": \"有害垃圾\"}\n",
    "garbage_index_classify = {\"其他垃圾\":\"0\",\"厨余垃圾\":\"1\", \"可回收物\":\"2\",\"有害垃圾\":\"3\"}\n",
    "\n",
    "data_list = []\n",
    "# rank1_garbage_classify_rule = {}\n",
    "for k,v in garbage_classify_rule.items():\n",
    "    rank1_k = v.split('/')[0] \n",
    "    rank1_v = k\n",
    "    data_list.append([\n",
    "        rank1_k,\n",
    "        int(garbage_index_classify[rank1_k]),\n",
    "        int(rank1_v)])\n",
    "\n",
    "print(data_list)\n",
    "# 获取一级分类label 对应的原始数据label \n",
    "rank_k_v_dict = {}\n",
    "for data in data_list:\n",
    "    k = data[2] # 原标签\n",
    "    v = data[1]# 新标签\n",
    "    rank_k_v_dict[k]=v\n",
    "print(rank_k_v_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整体数据探测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on function walk in module os:\n\nwalk(top, topdown=True, onerror=None, followlinks=False)\n    Directory tree generator.\n    \n    For each directory in the directory tree rooted at top (including top\n    itself, but excluding '.' and '..'), yields a 3-tuple\n    \n        dirpath, dirnames, filenames\n    \n    dirpath is a string, the path to the directory.  dirnames is a list of\n    the names of the subdirectories in dirpath (excluding '.' and '..').\n    filenames is a list of the names of the non-directory files in dirpath.\n    Note that the names in the lists are just names, with no path components.\n    To get a full path (which begins with top) to a file or directory in\n    dirpath, do os.path.join(dirpath, name).\n    \n    If optional arg 'topdown' is true or not specified, the triple for a\n    directory is generated before the triples for any of its subdirectories\n    (directories are generated top down).  If topdown is false, the triple\n    for a directory is generated after the triples for all of its\n    subdirectories (directories are generated bottom up).\n    \n    When topdown is true, the caller can modify the dirnames list in-place\n    (e.g., via del or slice assignment), and walk will only recurse into the\n    subdirectories whose names remain in dirnames; this can be used to prune the\n    search, or to impose a specific order of visiting.  Modifying dirnames when\n    topdown is false is ineffective, since the directories in dirnames have\n    already been generated by the time dirnames itself is generated. No matter\n    the value of topdown, the list of subdirectories is retrieved before the\n    tuples for the directory and its subdirectories are generated.\n    \n    By default errors from the os.scandir() call are ignored.  If\n    optional arg 'onerror' is specified, it should be a function; it\n    will be called with one argument, an OSError instance.  It can\n    report the error to continue with the walk, or raise the exception\n    to abort the walk.  Note that the filename is available as the\n    filename attribute of the exception object.\n    \n    By default, os.walk does not follow symbolic links to subdirectories on\n    systems that support them.  In order to get this functionality, set the\n    optional argument 'followlinks' to true.\n    \n    Caution:  if you pass a relative pathname for top, don't change the\n    current working directory between resumptions of walk.  walk never\n    changes the current directory, and assumes that the client doesn't\n    either.\n    \n    Example:\n    \n    import os\n    from os.path import join, getsize\n    for root, dirs, files in os.walk('python/Lib/email'):\n        print(root, \"consumes\", end=\"\")\n        print(sum([getsize(join(root, name)) for name in files]), end=\"\")\n        print(\"bytes in\", len(files), \"non-directory files\")\n        if 'CVS' in dirs:\n            dirs.remove('CVS')  # don't visit CVS directories\n\n"
    }
   ],
   "source": [
    "import os\n",
    "from os import walk\n",
    "help(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "************************************************************\nDirectory path: ../../data/garbage_classify/train_data\ntotal examples: 29604\nFile name example: ['img_1.jpg', 'img_1.txt', 'img_10.jpg', 'img_10.txt', 'img_100.jpg']\n"
    }
   ],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "base_path = '../../data/'\n",
    "data_path = os.path.join(base_path, 'garbage_classify/train_data')\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(data_path):\n",
    "    if len(filenames) > 0:\n",
    "        print(\"*\"*60)\n",
    "        print(\"Directory path:\", dirpath)\n",
    "        print(\"total examples:\", len(filenames))\n",
    "        print(\"File name example:\", filenames[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来分析*.txt读取内容，然后获取img.txt\n",
    "\n",
    "首先，我们需要 匹配txt 文件进行输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os\n",
    "\n",
    "\n",
    "def get_img_info():\n",
    "    data_path_txt = os.path.join(data_path, '*.txt')\n",
    "    # print(data_path_txt)\n",
    "    txt_file_list = glob(data_path_txt)\n",
    "\n",
    "    # 存储txt文件\n",
    "    img_path_txt = 'img.txt'\n",
    "    img_path_list = []\n",
    "    img_label_dict = dict() # <label, count>\n",
    "    img_name2label_dict = dict()\n",
    "\n",
    "    for file_path in txt_file_list:\n",
    "        with open(file_path, 'r') as f:\n",
    "            line = f.readline()\n",
    "        line = line.strip() # 去掉空格\n",
    "        img_name = line.split(',')[0]\n",
    "        img_label = line.split(',')[1]\n",
    "        img_label = int(img_label)\n",
    "        # 图片路径\n",
    "        img_name_path = os.path.join(base_path, 'garbage_classify/train_data/{}'.format(img_name))\n",
    "        img_path_list.append(\n",
    "            {\n",
    "                'img_name_path': img_name_path,\n",
    "                'img_label': img_label\n",
    "            }\n",
    "        )\n",
    "    return img_path_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "img_path_list: [{'img_name_path': '../../data/garbage_classify/train_data/img_1.jpg', 'img_label': 0}, {'img_name_path': '../../data/garbage_classify/train_data/img_10.jpg', 'img_label': 0}, {'img_name_path': '../../data/garbage_classify/train_data/img_100.jpg', 'img_label': 0}, {'img_name_path': '../../data/garbage_classify/train_data/img_1000.jpg', 'img_label': 2}, {'img_name_path': '../../data/garbage_classify/train_data/img_10000.jpg', 'img_label': 21}, {'img_name_path': '../../data/garbage_classify/train_data/img_10001.jpg', 'img_label': 21}, {'img_name_path': '../../data/garbage_classify/train_data/img_10002.jpg', 'img_label': 21}, {'img_name_path': '../../data/garbage_classify/train_data/img_10003.jpg', 'img_label': 21}, {'img_name_path': '../../data/garbage_classify/train_data/img_10005.jpg', 'img_label': 21}, {'img_name_path': '../../data/garbage_classify/train_data/img_10006.jpg', 'img_label': 21}]\n"
    }
   ],
   "source": [
    "print(\"img_path_list:\", get_img_info()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对img_path_list的img_label 进行修改为一级分类的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "img_path_list: [{'img_name_path': '../../data/garbage_classify/train_data/img_1.jpg', 'img_label': 0}, {'img_name_path': '../../data/garbage_classify/train_data/img_10.jpg', 'img_label': 0}, {'img_name_path': '../../data/garbage_classify/train_data/img_100.jpg', 'img_label': 0}, {'img_name_path': '../../data/garbage_classify/train_data/img_1000.jpg', 'img_label': 0}]\nimg_label_dict: {0: 1652, 2: 8611, 3: 1150, 1: 3389}\n"
    }
   ],
   "source": [
    "img_path_list = []\n",
    "img_label_dict = {}\n",
    "\n",
    "for img_info in get_img_info():\n",
    "    img_label = img_info['img_label'] # 修改前\n",
    "    img_label = rank_k_v_dict[img_label]\n",
    "    img_info.update({'img_label': img_label}) # 修正之后标签\n",
    "    # 图片路径+标签\n",
    "    img_path_list.append(img_info)\n",
    "\n",
    "    # 统计每个标签出现的次数\n",
    "    img_label = int(img_label)\n",
    "    img_label_count = img_label_dict.get(img_label, 0)\n",
    "\n",
    "    if img_label_count:\n",
    "        img_label_dict[img_label] = img_label_count + 1\n",
    "    else:\n",
    "        img_label_dict[img_label] = 1\n",
    "    \n",
    "print('img_path_list:', img_path_list[:4])\n",
    "print('img_label_dict:', img_label_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据不同类别分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{0: 1652, 1: 3389, 2: 8611, 3: 1150}\n{'0': '其他垃圾', '1': '厨余垃圾', '2': '可回收物', '3': '有害垃圾'}\n['其他垃圾', '厨余垃圾', '可回收物', '有害垃圾']\n[1652, 3389, 8611, 1150]\n"
    }
   ],
   "source": [
    "img_label_dict = dict(sorted(img_label_dict.items()))\n",
    "print(img_label_dict)\n",
    "print(garbage_classify_index)\n",
    "print([garbage_classify_index[str(k)] for k in img_label_dict.keys()])\n",
    "print(list(img_label_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Users\\lzn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyecharts\\charts\\chart.py:14: PendingDeprecationWarning: pyecharts 所有图表类型将在 v1.9.0 版本开始强制使用 ChartItem 进行数据项配置 :)\n  super().__init__(init_opts=init_opts)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pyecharts.render.display.HTML at 0x16f4b8cd780>",
      "text/html": "\n<script>\n    require.config({\n        paths: {\n            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n        }\n    });\n</script>\n\n        <div id=\"44fef5cbd3a44d90b03591820ba36878\" style=\"width:900px; height:500px;\"></div>\n\n<script>\n        require(['echarts'], function(echarts) {\n                var chart_44fef5cbd3a44d90b03591820ba36878 = echarts.init(\n                    document.getElementById('44fef5cbd3a44d90b03591820ba36878'), 'white', {renderer: 'canvas'});\n                var option_44fef5cbd3a44d90b03591820ba36878 = {\n    \"animation\": true,\n    \"animationThreshold\": 2000,\n    \"animationDuration\": 1000,\n    \"animationEasing\": \"cubicOut\",\n    \"animationDelay\": 0,\n    \"animationDurationUpdate\": 300,\n    \"animationEasingUpdate\": \"cubicOut\",\n    \"animationDelayUpdate\": 0,\n    \"color\": [\n        \"#c23531\",\n        \"#2f4554\",\n        \"#61a0a8\",\n        \"#d48265\",\n        \"#749f83\",\n        \"#ca8622\",\n        \"#bda29a\",\n        \"#6e7074\",\n        \"#546570\",\n        \"#c4ccd3\",\n        \"#f05b72\",\n        \"#ef5b9c\",\n        \"#f47920\",\n        \"#905a3d\",\n        \"#fab27b\",\n        \"#2a5caa\",\n        \"#444693\",\n        \"#726930\",\n        \"#b2d235\",\n        \"#6d8346\",\n        \"#ac6767\",\n        \"#1d953f\",\n        \"#6950a1\",\n        \"#918597\"\n    ],\n    \"series\": [\n        {\n            \"type\": \"bar\",\n            \"legendHoverLink\": true,\n            \"data\": [\n                1652,\n                3389,\n                8611,\n                1150\n            ],\n            \"showBackground\": false,\n            \"barMinHeight\": 0,\n            \"barCategoryGap\": \"20%\",\n            \"barGap\": \"30%\",\n            \"large\": false,\n            \"largeThreshold\": 400,\n            \"seriesLayoutBy\": \"column\",\n            \"datasetIndex\": 0,\n            \"clip\": true,\n            \"zlevel\": 0,\n            \"z\": 2,\n            \"label\": {\n                \"show\": true,\n                \"position\": \"top\",\n                \"margin\": 8\n            }\n        }\n    ],\n    \"legend\": [\n        {\n            \"data\": [\n                \"\"\n            ],\n            \"selected\": {\n                \"\": true\n            },\n            \"show\": true,\n            \"padding\": 5,\n            \"itemGap\": 10,\n            \"itemWidth\": 25,\n            \"itemHeight\": 14\n        }\n    ],\n    \"tooltip\": {\n        \"show\": true,\n        \"trigger\": \"item\",\n        \"triggerOn\": \"mousemove|click\",\n        \"axisPointer\": {\n            \"type\": \"line\"\n        },\n        \"showContent\": true,\n        \"alwaysShowContent\": false,\n        \"showDelay\": 0,\n        \"hideDelay\": 100,\n        \"textStyle\": {\n            \"fontSize\": 14\n        },\n        \"borderWidth\": 0,\n        \"padding\": 5\n    },\n    \"xAxis\": [\n        {\n            \"show\": true,\n            \"scale\": false,\n            \"nameLocation\": \"end\",\n            \"nameGap\": 15,\n            \"gridIndex\": 0,\n            \"axisLabel\": {\n                \"show\": true,\n                \"position\": \"top\",\n                \"rotate\": 15,\n                \"margin\": 8\n            },\n            \"inverse\": false,\n            \"offset\": 0,\n            \"splitNumber\": 5,\n            \"minInterval\": 0,\n            \"splitLine\": {\n                \"show\": false,\n                \"lineStyle\": {\n                    \"show\": true,\n                    \"width\": 1,\n                    \"opacity\": 1,\n                    \"curveness\": 0,\n                    \"type\": \"solid\"\n                }\n            },\n            \"data\": [\n                \"\\u5176\\u4ed6\\u5783\\u573e\",\n                \"\\u53a8\\u4f59\\u5783\\u573e\",\n                \"\\u53ef\\u56de\\u6536\\u7269\",\n                \"\\u6709\\u5bb3\\u5783\\u573e\"\n            ]\n        }\n    ],\n    \"yAxis\": [\n        {\n            \"show\": true,\n            \"scale\": false,\n            \"nameLocation\": \"end\",\n            \"nameGap\": 15,\n            \"gridIndex\": 0,\n            \"inverse\": false,\n            \"offset\": 0,\n            \"splitNumber\": 5,\n            \"minInterval\": 0,\n            \"splitLine\": {\n                \"show\": false,\n                \"lineStyle\": {\n                    \"show\": true,\n                    \"width\": 1,\n                    \"opacity\": 1,\n                    \"curveness\": 0,\n                    \"type\": \"solid\"\n                }\n            }\n        }\n    ],\n    \"title\": [\n        {\n            \"text\": \"\\u5783\\u573e\\u5206\\u7c7b4\\u7c7b\\u5783\\u573e\\u6570\\u91cf\\u7edf\\u8ba1\",\n            \"padding\": 5,\n            \"itemGap\": 10\n        }\n    ]\n};\n                chart_44fef5cbd3a44d90b03591820ba36878.setOption(option_44fef5cbd3a44d90b03591820ba36878);\n        });\n    </script>\n"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# 导入库\n",
    "from pyecharts import options as opts \n",
    "from pyecharts.charts import Bar\n",
    "\n",
    "# 构建满足pyecharts 格式数据\n",
    "x = [garbage_classify_index[str(k)] for k in img_label_dict.keys()]\n",
    "y = list(img_label_dict.values())\n",
    "\n",
    "# 创建Bar \n",
    "bar = Bar()\n",
    "\n",
    "bar.add_xaxis(xaxis_data=x)\n",
    "bar.add_yaxis(series_name='', y_axis=y)\n",
    "\n",
    "# 设置全局参数\n",
    "bar.set_global_opts(\n",
    "    title_opts=opts.TitleOpts(title=\"垃圾分类4类垃圾数量统计\"),\n",
    "    xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=15))\n",
    ")\n",
    "\n",
    "# 展示图标\n",
    "bar.render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据分析，可以得出一下的结论：\n",
    "\n",
    "1. 公共4 个分类，如上图分析Bar 图所示\n",
    "\n",
    "2. 较少数据为其他垃圾\n",
    "\n",
    "3. 较多的数据类别可以回收的垃圾\n",
    "\n",
    "\n",
    "我们的模型通过深度学习的迁移模型来完成，小数据量的样本也可以达到很好的效果，这些数据可以直接参与模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "14802"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "len(img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'img_name_path': '../../data/garbage_classify/train_data/img_1.jpg',\n 'img_label': 0}"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "img_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train_size: 11841\nval_img_list: 2961\n"
    }
   ],
   "source": [
    "import random \n",
    "random.shuffle(img_path_list)\n",
    "\n",
    "# 0.8 0.2 切分\n",
    "img_count = len(img_path_list)\n",
    "train_img_list = img_path_list[:int(img_count*0.8)]\n",
    "val_img_list = img_path_list[int(img_count*0.8):]\n",
    "\n",
    "print(\"train_size:\", len(train_img_list))\n",
    "print(\"val_img_list:\", len(val_img_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据切分之后，我们生成训练和验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "路径已经存在\n"
    }
   ],
   "source": [
    "import shutil \n",
    "\n",
    "train_val_data_path = os.path.join(\n",
    "    base_path,\n",
    "    'refuse_data'\n",
    ")\n",
    "\n",
    "if os.path.exists(train_val_data_path):\n",
    "    print(\"路径已经存在\")\n",
    "else:\n",
    "    os.makedirs(train_val_data_path)\n",
    "    print(\"生成路径\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练数据处理\n",
    "with open(os.path.join(train_val_data_path,'train.txt'), 'w') as f:\n",
    "    for img_dict in train_img_list:\n",
    "        # 文本格式数据\n",
    "        img_name_path = img_dict['img_name_path']\n",
    "        img_label = img_dict['img_label']\n",
    "\n",
    "        f.write(\"{}\\t{}\\n\".format(img_name_path, img_label))\n",
    "\n",
    "        # 图片-标签目录\n",
    "        garbage_classify_dir = os.path.join(\n",
    "            train_val_data_path,\n",
    "            'train/{}'.format(img_label)\n",
    "        )\n",
    "\n",
    "        if not os.path.exists(garbage_classify_dir):\n",
    "            os.makedirs(garbage_classify_dir)\n",
    "        \n",
    "        # 拷贝数据到目录下\n",
    "        shutil.copy(img_name_path, garbage_classify_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 2961/2961 [00:43<00:00, 67.32it/s]\n"
    }
   ],
   "source": [
    "with open(os.path.join(train_val_data_path, 'val.txt'),'w') as f:\n",
    "    for img_dict in tqdm(val_img_list):\n",
    "        # 文本格式的数据\n",
    "        img_name_path = img_dict['img_name_path']\n",
    "        img_label = img_dict['img_label']\n",
    "        f.write(\"{}\\t{}\\n\".format(img_name_path, img_label))\n",
    "\n",
    "        # 图片-目录\n",
    "        dirname = os.path.join(\n",
    "            train_val_data_path,\n",
    "            \"val/{}\".format(img_label)\n",
    "            )\n",
    "\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "        \n",
    "        # 复制\n",
    "        shutil.copy(img_name_path, dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "|—— test\n",
    "|   |—— 0\n",
    "|   |—— 1\n",
    "|   |—— 2\n",
    "|   |—— 3\n",
    "|—— train\n",
    "|   |—— 0\n",
    "|   |—— 1\n",
    "|   |—— 2\n",
    "|   |—— 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我们来分析 切分后的验证集和训练集的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../../data/refuse_data/train.txt\n../../data/refuse_data/val.txt\n"
    }
   ],
   "source": [
    "train_path = os.path.join(\n",
    "    base_path,\n",
    "    'refuse_data/train.txt'\n",
    ")\n",
    "\n",
    "test_path = os.path.join(\n",
    "    base_path,\n",
    "    'refuse_data/val.txt'\n",
    ")\n",
    "print(train_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "ipykernel_launcher:4: ResourceWarning: unclosed file <_io.TextIOWrapper name='../../data/refuse_data/train.txt' mode='r' encoding='cp936'>\nipykernel_launcher:4: ResourceWarning: unclosed file <_io.TextIOWrapper name='../../data/refuse_data/val.txt' mode='r' encoding='cp936'>\n"
    }
   ],
   "source": [
    "def get_label_idx_list(data_path):\n",
    "    label_idx_list = []\n",
    "    import codecs\n",
    "    for line in codecs.open(data_path, 'r'):\n",
    "        line = line.strip()\n",
    "        label_idx = line.split('\\t')[1]\n",
    "        label_idx_list.append(int(label_idx))\n",
    "    return label_idx_list\n",
    "\n",
    "from collections import Counter \n",
    "train_dict = dict(Counter(get_label_idx_list(train_path)))\n",
    "test_dict = dict(Counter(get_label_idx_list(test_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train_dict: {0: 1300, 1: 2701, 2: 6912, 3: 928}\ntest_dict: {0: 352, 1: 688, 2: 1699, 3: 222}\ngarbage_classify_index: {'0': '其他垃圾', '1': '厨余垃圾', '2': '可回收物', '3': '有害垃圾'}\n"
    }
   ],
   "source": [
    "train_dict = dict(sorted(train_dict.items()))\n",
    "test_dict = dict(sorted(test_dict.items()))\n",
    "\n",
    "print(\"train_dict:\", train_dict)\n",
    "print(\"test_dict:\", test_dict)\n",
    "\n",
    "print(\"garbage_classify_index:\", garbage_classify_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts \n",
    "from pyecharts.charts import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Users\\lzn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyecharts\\charts\\chart.py:14: PendingDeprecationWarning: pyecharts 所有图表类型将在 v1.9.0 版本开始强制使用 ChartItem 进行数据项配置 :)\n  super().__init__(init_opts=init_opts)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pyecharts.render.display.HTML at 0x16f4dade9b0>",
      "text/html": "\n<script>\n    require.config({\n        paths: {\n            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n        }\n    });\n</script>\n\n        <div id=\"1fa8f4dd7aa642c1aa1fd45a73758292\" style=\"width:900px; height:500px;\"></div>\n\n<script>\n        require(['echarts'], function(echarts) {\n                var chart_1fa8f4dd7aa642c1aa1fd45a73758292 = echarts.init(\n                    document.getElementById('1fa8f4dd7aa642c1aa1fd45a73758292'), 'white', {renderer: 'canvas'});\n                var option_1fa8f4dd7aa642c1aa1fd45a73758292 = {\n    \"animation\": true,\n    \"animationThreshold\": 2000,\n    \"animationDuration\": 1000,\n    \"animationEasing\": \"cubicOut\",\n    \"animationDelay\": 0,\n    \"animationDurationUpdate\": 300,\n    \"animationEasingUpdate\": \"cubicOut\",\n    \"animationDelayUpdate\": 0,\n    \"color\": [\n        \"#c23531\",\n        \"#2f4554\",\n        \"#61a0a8\",\n        \"#d48265\",\n        \"#749f83\",\n        \"#ca8622\",\n        \"#bda29a\",\n        \"#6e7074\",\n        \"#546570\",\n        \"#c4ccd3\",\n        \"#f05b72\",\n        \"#ef5b9c\",\n        \"#f47920\",\n        \"#905a3d\",\n        \"#fab27b\",\n        \"#2a5caa\",\n        \"#444693\",\n        \"#726930\",\n        \"#b2d235\",\n        \"#6d8346\",\n        \"#ac6767\",\n        \"#1d953f\",\n        \"#6950a1\",\n        \"#918597\"\n    ],\n    \"series\": [\n        {\n            \"type\": \"bar\",\n            \"name\": \"Train\",\n            \"legendHoverLink\": true,\n            \"data\": [\n                1300,\n                2701,\n                6912,\n                928\n            ],\n            \"showBackground\": false,\n            \"barMinHeight\": 0,\n            \"barCategoryGap\": \"20%\",\n            \"barGap\": \"30%\",\n            \"large\": false,\n            \"largeThreshold\": 400,\n            \"seriesLayoutBy\": \"column\",\n            \"datasetIndex\": 0,\n            \"clip\": true,\n            \"zlevel\": 0,\n            \"z\": 2,\n            \"label\": {\n                \"show\": true,\n                \"position\": \"top\",\n                \"margin\": 8\n            }\n        },\n        {\n            \"type\": \"bar\",\n            \"name\": \"Val\",\n            \"legendHoverLink\": true,\n            \"data\": [\n                352,\n                688,\n                1699,\n                222\n            ],\n            \"showBackground\": false,\n            \"barMinHeight\": 0,\n            \"barCategoryGap\": \"20%\",\n            \"barGap\": \"30%\",\n            \"large\": false,\n            \"largeThreshold\": 400,\n            \"seriesLayoutBy\": \"column\",\n            \"datasetIndex\": 0,\n            \"clip\": true,\n            \"zlevel\": 0,\n            \"z\": 2,\n            \"label\": {\n                \"show\": true,\n                \"position\": \"top\",\n                \"margin\": 8\n            }\n        }\n    ],\n    \"legend\": [\n        {\n            \"data\": [\n                \"Train\",\n                \"Val\"\n            ],\n            \"selected\": {\n                \"Train\": true,\n                \"Val\": true\n            },\n            \"show\": true,\n            \"padding\": 5,\n            \"itemGap\": 10,\n            \"itemWidth\": 25,\n            \"itemHeight\": 14\n        }\n    ],\n    \"tooltip\": {\n        \"show\": true,\n        \"trigger\": \"item\",\n        \"triggerOn\": \"mousemove|click\",\n        \"axisPointer\": {\n            \"type\": \"line\"\n        },\n        \"showContent\": true,\n        \"alwaysShowContent\": false,\n        \"showDelay\": 0,\n        \"hideDelay\": 100,\n        \"textStyle\": {\n            \"fontSize\": 14\n        },\n        \"borderWidth\": 0,\n        \"padding\": 5\n    },\n    \"xAxis\": [\n        {\n            \"show\": true,\n            \"scale\": false,\n            \"nameLocation\": \"end\",\n            \"nameGap\": 15,\n            \"gridIndex\": 0,\n            \"axisLabel\": {\n                \"show\": true,\n                \"position\": \"top\",\n                \"rotate\": 15,\n                \"margin\": 8\n            },\n            \"inverse\": false,\n            \"offset\": 0,\n            \"splitNumber\": 5,\n            \"minInterval\": 0,\n            \"splitLine\": {\n                \"show\": false,\n                \"lineStyle\": {\n                    \"show\": true,\n                    \"width\": 1,\n                    \"opacity\": 1,\n                    \"curveness\": 0,\n                    \"type\": \"solid\"\n                }\n            },\n            \"data\": [\n                \"0-\\u5176\\u4ed6\\u5783\\u573e\",\n                \"1-\\u53a8\\u4f59\\u5783\\u573e\",\n                \"2-\\u53ef\\u56de\\u6536\\u7269\",\n                \"3-\\u6709\\u5bb3\\u5783\\u573e\"\n            ]\n        }\n    ],\n    \"yAxis\": [\n        {\n            \"show\": true,\n            \"scale\": false,\n            \"nameLocation\": \"end\",\n            \"nameGap\": 15,\n            \"gridIndex\": 0,\n            \"inverse\": false,\n            \"offset\": 0,\n            \"splitNumber\": 5,\n            \"minInterval\": 0,\n            \"splitLine\": {\n                \"show\": false,\n                \"lineStyle\": {\n                    \"show\": true,\n                    \"width\": 1,\n                    \"opacity\": 1,\n                    \"curveness\": 0,\n                    \"type\": \"solid\"\n                }\n            }\n        }\n    ],\n    \"title\": [\n        {\n            \"text\": \"\\u5783\\u573e\\u5206\\u7c7b \\u4e0d\\u540c\\u7c7b\\u522b\\u6570\\u636e\\u6570\\u91cf\\u7edf\\u8ba1\",\n            \"padding\": 5,\n            \"itemGap\": 10\n        }\n    ]\n};\n                chart_1fa8f4dd7aa642c1aa1fd45a73758292.setOption(option_1fa8f4dd7aa642c1aa1fd45a73758292);\n        });\n    </script>\n"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "# 构建需要的数据\n",
    "\n",
    "\n",
    "\n",
    "# 构建bar\n",
    "# bar = Bar(init_opts=opts.InitOpts())\n",
    "bar = Bar()\n",
    "\n",
    "assert len(train_dict.keys()) == len(test_dict.keys())\n",
    "\n",
    "x = [\"{}-{}\".format(\n",
    "                label_idx,\n",
    "                garbage_classify_index.get(str(label_idx),\"\")\n",
    "            )\n",
    "        for label_idx in img_label_dict.keys()] \n",
    "\n",
    "bar.add_xaxis(xaxis_data=list(x))\n",
    "bar.add_yaxis(series_name='Train',\n",
    "                y_axis=list(train_dict.values()))\n",
    "bar.add_yaxis(series_name='Val',\n",
    "                y_axis=list(test_dict.values()))\n",
    "\n",
    "# 全局参数设置\n",
    "bar.set_global_opts(\n",
    "    title_opts=opts.TitleOpts(title=\"垃圾分类 不同类别数据数量统计\"),\n",
    "    xaxis_opts = opts.AxisOpts(\n",
    "        axislabel_opts=opts.LabelOpts(rotate=15)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 渲染图标\n",
    "bar.render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在选择好模型后，后续需要重点从数据层次上下手。\n",
    "\n",
    "* 类别分布不均衡，可以从网站上下载对应的图片数据，用于扩充我们的数据内容\n",
    "* 根据数据大小分布，我们这里把数据resize 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595126197581",
   "display_name": "Python 3.7.0 64-bit ('Continuum': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}